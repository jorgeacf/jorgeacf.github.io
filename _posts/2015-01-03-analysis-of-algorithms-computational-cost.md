---
layout: post
title: Algorithm analysis
excerpt_separator: <!--more-->
---

In this blog post I will write about the analysis of the cost in terms of memory and processor resources cost.
 
<!--more-->

## Introduction
An algorithm can be described as a set of computational instructions that receives a input in a form of a value or a set of values and returns or produces a output also as a value or a set of values. 

## What should we take in consideration to define a performance of an algorithm?

Itâ€™s important do define what we should measure if we need to predict the performance of the algorithm with different input values

 

## Order of growth of algorithms

 

**Constant**: Having a constant order of growth means that independently of the size of the algorithm input the time to execute will be always the same. For instance the instruction int i = 0; will always take the same time to complete.

**Logarithmic**: A logarithmic order of growth is typically when the algorithm divides the input in half.

**Linear**: A linear order of growth is when the algorithm loop through all the elements of the output.

**Linearithmic**:

**Quadratic**: A quadratic order of growth is when the algorithm have a double loop.

**Cubic**: A cubic order of growth is when the algorithm have a triple loop.

**Exponential**: An exponential order of growth is the worst in terms of scalability because the cost of the algorithm increases exponentially with the size of the input. Typically the algorithms to check all the subsets have this cost. 
 

## Worst-case and average-case analysis

 

## Summary of order of growth of algorithms

The figure below summarises the order of growths that we discussed in this post:


