---
layout: post
title: Character Encoding 101
author: Jorge Figueiredo
date:   2015-03-01 00:00:00
categories: [Algorithms, Basics]
comments: true
excerpt_separator: <!--more-->
---

Understanding the basics of character encoding is fundamental to any computer scientist.

<!--more-->

### Introduction

This is a subject that I personally confess that I was procrastinating to dig into more deeply until it was really necessary. The announced confusion and problems that we always ear about this is responsible for part of the reasons for myself and I believe a good portion of computer scientist and engineers to try to ignore this.

Basically what we are talking about here is how could we store text in a computer? Since computers only work with bits 0's and 1's and so to store text we need to encode the text characters in sequence of bits.

### A bit of history


### First things first


### Terms to retain 


### Summary


### But wait is it that simple?

The answer is no! Actually character encoding is a big mess. Let look to a couple of examples:

a)